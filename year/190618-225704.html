<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="【Python实例】让Python告诉你当前最火的电影是什么"><meta name="keywords" content="Python,电影,爬虫"><meta name="author" content="Teams Six,undefined"><meta name="copyright" content="Teams Six"><title>【Python实例】让Python告诉你当前最火的电影是什么【Teams Six】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="icon" href="/favicon.ico"><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="/js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.json","languages":{"hits_empty":"local_search.hits_empty"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
}</script></head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、需求与思路"><span class="toc-number">1.</span> <span class="toc-text">一、需求与思路</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1、需求"><span class="toc-number">2.</span> <span class="toc-text">1、需求</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2、思路"><span class="toc-number">3.</span> <span class="toc-text">2、思路</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二、开工"><span class="toc-number">4.</span> <span class="toc-text">二、开工</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1、发出请求"><span class="toc-number">5.</span> <span class="toc-text">1、发出请求</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2、数据传入"><span class="toc-number">6.</span> <span class="toc-text">2、数据传入</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三、数据提取"><span class="toc-number">7.</span> <span class="toc-text">三、数据提取</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1、电影名"><span class="toc-number">8.</span> <span class="toc-text">1、电影名</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2、豆瓣评分"><span class="toc-number">9.</span> <span class="toc-text">2、豆瓣评分</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3、评论数量"><span class="toc-number">10.</span> <span class="toc-text">3、评论数量</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4、简介"><span class="toc-number">11.</span> <span class="toc-text">4、简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#四、提取URL"><span class="toc-number">12.</span> <span class="toc-text">四、提取URL</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#五、表格生成"><span class="toc-number">13.</span> <span class="toc-text">五、表格生成</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#六、总结"><span class="toc-number">14.</span> <span class="toc-text">六、总结</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Teams Six</div><div class="author-info-description"></div><div class="links-buttons"><a class="links-button button-hover" href="https://github.com/teamssix" target="_blank">GitHub<i class="icon-dot bg-color3"></i></a><a class="links-button button-hover" href="https://me.csdn.net/qq_37683287" target="_blank">CSDN<i class="icon-dot bg-color0"></i></a><a class="links-button button-hover" href="https://twitter.com/TeamsSix" target="_blank">Twitter<i class="icon-dot bg-color2"></i></a><a class="links-button button-hover" href="https://instagram.com/TeamsSix" target="_blank">Instagram<i class="icon-dot bg-color3"></i></a><a class="links-button button-hover" href="https://www.youtube.com/channel/UCKeJhJYi_tmXWETzVxKbSvA" target="_blank">YouTube<i class="icon-dot bg-color5"></i></a><a class="links-button button-hover" href="https://space.bilibili.com/148389186" target="_blank">BiliBili<i class="icon-dot bg-color4"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="/archives"><span class="pull-top">日志</span><span class="pull-bottom">59</span></a><a class="author-info-articles-tags article-meta" href="/tags"><span class="pull-top">标签</span><span class="pull-bottom">79</span></a><a class="author-info-articles-categories article-meta" href="/categories"><span class="pull-top">分类</span><span class="pull-bottom">15</span></a></div><div class="friend-link"><a class="friend-link-text" target="_blank">欢迎关注本站微信公众号：TeamsSix</a><a class="friend-link-text" href="https://www.loongten.com/" target="_blank">友情链接：loongten</a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a></nav><div class="right-info"><a class="title-name" href="/">Teams Six</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">【Python实例】让Python告诉你当前最火的电影是什么</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2019-06-18 | 更新于 2019-12-24</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/Python-其他相关笔记/">Python 其他相关笔记</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/Python/">Python</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/电影/">电影</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/爬虫/">爬虫</a></div></div></div><div class="main-content"><p>话不多说，先让我们看看最终效果图：</p>
<a id="more"></a>
<p><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm1.png" alt><br>那么如何使用Python来获取这些信息呢？</p>
<h1 id="一、需求与思路"><a href="#一、需求与思路" class="headerlink" title="一、需求与思路"></a>一、需求与思路</h1><h1 id="1、需求"><a href="#1、需求" class="headerlink" title="1、需求"></a>1、需求</h1><p>首先要知道最近正在上映的电影的名称、评分、评论数等等，这些都可以在豆瓣上找得到，因此本次数据挖掘对象就确定为豆瓣电影官网。<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm2.png" alt></p>
<h1 id="2、思路"><a href="#2、思路" class="headerlink" title="2、思路"></a>2、思路</h1><p>a、调用requests模块向豆瓣电影官网发出请求<br>b、调用BeautifulSoup模块从返回的html中提取数据<br>c、调用pandas模块将提取的数据转为表格样式</p>
<h1 id="二、开工"><a href="#二、开工" class="headerlink" title="二、开工"></a>二、开工</h1><h1 id="1、发出请求"><a href="#1、发出请求" class="headerlink" title="1、发出请求"></a>1、发出请求</h1><p>设置好headers,url，调用requests模块向目标网站发出请求，最后结果存储在res中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'</span>&#125;</span><br><span class="line">url = <span class="string">'https://movie.douban.com/cinema/nowplaying/beijing/'</span></span><br><span class="line">res = requests.get(url,headers = headers)</span><br></pre></td></tr></table></figure>

<h1 id="2、数据传入"><a href="#2、数据传入" class="headerlink" title="2、数据传入"></a>2、数据传入</h1><p>将html文本传入BeautifulSoup中，指定解析器为html.parser，并将解析内容传入soup</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(res.text,<span class="string">'html.parser'</span>)</span><br></pre></td></tr></table></figure>

<h1 id="三、数据提取"><a href="#三、数据提取" class="headerlink" title="三、数据提取"></a>三、数据提取</h1><p>在介绍数据提取之前需要先介绍一个插件：infolite，这款插件可以直接查看到控件路径，而不需要到复杂的开发人员工具中就行查看。</p>
<h1 id="1、电影名"><a href="#1、电影名" class="headerlink" title="1、电影名"></a>1、电影名</h1><p>打开电影详情页面，找到电影名控件路径<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm3.png" alt><br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm4.png" alt><br>最终修改为以下结果得到电影名称</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insoup.select(<span class="string">'h1'</span>)[<span class="number">0</span>].text.split()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm5.png" alt></p>
<h1 id="2、豆瓣评分"><a href="#2、豆瓣评分" class="headerlink" title="2、豆瓣评分"></a>2、豆瓣评分</h1><p>根据同样原理可得到该电影的评分<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm6.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insoup.select(<span class="string">'.rating_num'</span>)[<span class="number">0</span>].text</span><br></pre></td></tr></table></figure>

<p><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm7.png" alt></p>
<h1 id="3、评论数量"><a href="#3、评论数量" class="headerlink" title="3、评论数量"></a>3、评论数量</h1><p>依旧是一样的思路，先利用InfoLite找到控件路径，再利用bs4模块提取对应内容。<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm8.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insoup.select(<span class="string">'.mod-hd a'</span>)[<span class="number">1</span>].text.split()[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm9.png" alt></p>
<h1 id="4、简介"><a href="#4、简介" class="headerlink" title="4、简介"></a>4、简介</h1><p>对于简介因为里面有很多空格换行等，所以这里使用了正则替换空格。<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm10.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(<span class="string">'\s'</span>,<span class="string">''</span>,insoup.select(<span class="string">'.related-info span'</span>)[<span class="number">0</span>].text)</span><br></pre></td></tr></table></figure>

<p><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm11.png" alt><br>这里写个函数，为实现传入一个URL，返回该URL中信息的功能，最终四项都将传入result字典中，所以接下来要做的就是如何获取URL。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pages</span><span class="params">(url)</span>:</span></span><br><span class="line">    result = &#123;&#125;</span><br><span class="line">    inres = requests.get(url,headers = headers)</span><br><span class="line">    insoup = BeautifulSoup(inres.text,<span class="string">'html.parser'</span>)</span><br><span class="line">    </span><br><span class="line">    result[<span class="string">'电影名'</span>] = insoup.select(<span class="string">'h1'</span>)[<span class="number">0</span>].text.split()[<span class="number">0</span>]</span><br><span class="line">    result[<span class="string">'豆瓣评分'</span>] = insoup.select(<span class="string">'.rating_num'</span>)[<span class="number">0</span>].text</span><br><span class="line">    result[<span class="string">'评论数量'</span>] = insoup.select(<span class="string">'.mod-hd a'</span>)[<span class="number">1</span>].text.split()[<span class="number">1</span>]</span><br><span class="line">    result[<span class="string">'简介'</span>] = re.sub(<span class="string">'\s'</span>,<span class="string">''</span>,insoup.select(<span class="string">'.related-info span'</span>)[<span class="number">0</span>].text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<h1 id="四、提取URL"><a href="#四、提取URL" class="headerlink" title="四、提取URL"></a>四、提取URL</h1><p>因为我们要找的电影是正在上映的电影，因此从正在上映的电影列表中提取URL即可。<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm12.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">'https://movie.douban.com/cinema/nowplaying/beijing/'</span></span><br><span class="line">res = requests.get(url,headers = headers)</span><br><span class="line">soup = BeautifulSoup(res.text,<span class="string">'html.parser'</span>)</span><br></pre></td></tr></table></figure>

<p>在soup中含有这些链接，soup.select()是列表类型，有的列表项含有URL，有的不含有，并且在调试过程中发现有的含有链接的却没有评分信息。<br>因此在以下语句中URL利用select存到urls中，利用判断语句来筛选掉一些没有评分的电影。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pools = []</span><br><span class="line"><span class="keyword">for</span> links <span class="keyword">in</span> soup.select(<span class="string">'ul'</span>):</span><br><span class="line">    urls = links.select(<span class="string">'a'</span>)[<span class="number">0</span>][<span class="string">'href'</span>]</span><br><span class="line">    <span class="keyword">if</span> len(links.select(<span class="string">'.subject-rate'</span>)) &gt; <span class="number">0</span> :</span><br><span class="line">        pools.append(pages(urls))</span><br></pre></td></tr></table></figure>

<p>最终，每个URL的信息都被添加到pools数组中，但是这个时候直接输出pools会很乱，因此接下来要做的就是生成表格。<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm13.png" alt></p>
<h1 id="五、表格生成"><a href="#五、表格生成" class="headerlink" title="五、表格生成"></a>五、表格生成</h1><p>生成表格的方法也非常简单</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line">df = pandas.DataFrame(pools)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>

<p><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm14.png" alt><br>不过这样不够明显，因此我们可以将简介放到后面，再排序一下<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm15.png" alt></p>
<h1 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h1><p>上面一张图可以明显看到今天的四个贺岁电影中，《流浪星球》不管是豆瓣评分还是评论的数量都是第一个，倒也是实至名归。<br>在整个过程中，碰到了很多问题，其中不乏有还未解决的问题，比如在提取电影标签的时候，因为正则使用的不熟而一直没有被很好的提取出来。<br><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/hotfilm16.png" alt><br>在做这个数据挖掘之前，还做了新浪新闻的信息抓取，这个电影信息的数据挖掘也相当于是练练手，后面还有的导出文档、导出到数据库的功能就没有做演示了，也是几行代码的事情。<br>用了一段时间Python后，真的不得不感叹到Python的强大之处，下面就把以上项目的全部代码展示出来吧，另外我还是个新手，代码写得十分笨拙，大佬还请绕步。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'</span>&#125;</span><br><span class="line">url = <span class="string">'https://movie.douban.com/cinema/nowplaying/beijing/'</span></span><br><span class="line">res = requests.get(url,headers = headers)</span><br><span class="line">soup = BeautifulSoup(res.text,<span class="string">'html.parser'</span>)</span><br><span class="line">pools = []</span><br><span class="line"><span class="keyword">for</span> links <span class="keyword">in</span> soup.select(<span class="string">'ul'</span>):</span><br><span class="line">    urls = links.select(<span class="string">'a'</span>)[<span class="number">0</span>][<span class="string">'href'</span>]</span><br><span class="line">    <span class="keyword">if</span> len(links.select(<span class="string">'.subject-rate'</span>)) &gt; <span class="number">0</span> :</span><br><span class="line">        pools.append(pages(urls))</span><br><span class="line">df = pandas.DataFrame(pools,columns = [<span class="string">'电影名'</span>,<span class="string">'豆瓣评分'</span>,<span class="string">'评论数量'</span>,<span class="string">'简介'</span>])</span><br><span class="line">df.sort_values(<span class="string">'豆瓣评分'</span>,inplace = <span class="literal">True</span>,ascending = <span class="literal">False</span>)</span><br><span class="line">df</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pages</span><span class="params">(url)</span>:</span></span><br><span class="line">    result = &#123;&#125;</span><br><span class="line">    inres = requests.get(url,headers = headers)</span><br><span class="line">    insoup = BeautifulSoup(inres.text,<span class="string">'html.parser'</span>)</span><br><span class="line">    </span><br><span class="line">    result[<span class="string">'电影名'</span>] = insoup.select(<span class="string">'h1'</span>)[<span class="number">0</span>].text.split()[<span class="number">0</span>]</span><br><span class="line">    result[<span class="string">'豆瓣评分'</span>] = insoup.select(<span class="string">'.rating_num'</span>)[<span class="number">0</span>].text</span><br><span class="line">    result[<span class="string">'评论数量'</span>] = insoup.select(<span class="string">'.mod-hd a'</span>)[<span class="number">1</span>].text.split()[<span class="number">1</span>]</span><br><span class="line">    result[<span class="string">'简介'</span>] = re.sub(<span class="string">'\s'</span>,<span class="string">''</span>,insoup.select(<span class="string">'.related-info span'</span>)[<span class="number">0</span>].text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<p><img src="https://teamssix.oss-cn-hangzhou.aliyuncs.com/TeamsSix_Subscription_Logo2.png" alt></p>
</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Teams Six</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="https://www.teamssix.com/year/190618-225704.html">https://www.teamssix.com/year/190618-225704.html</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.teamssix.com">Teams Six</a>！</span></div></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/year/190619-202702.html"><i class="fas fa-angle-left">&nbsp;</i><span>【Python实例】让Python告诉你B站观影指南</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/year/190615-013724.html"><span>【漏洞复现 CVE 2019-0708】17年的勒索病毒又双叕卷土重来了？</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2020 By Teams Six</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--></body></html>